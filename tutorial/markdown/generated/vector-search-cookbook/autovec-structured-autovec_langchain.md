---
# frontmatter
path: "/tutorial-couchbase-capella-autovectorization-workflows-with-structured-data-and-langchain"
title: Auto-Vectorization of Strucutured Data with Couchbase Capella AI Services
short_title: Auto-Vectorization with Couchbase and Semantic Search using LangChain
description:
  - Learn how to use Couchbase Capella's AI Services auto-vectorization feature to automatically convert your structured data into vector embeddings. 
  - To learn about the auto-vectorization of unstuctured data read the following [tutorial](tutorial-couchbase-autovectorization-workdlows-with-unstructured-data-and-langchain).
  - This tutorial demonstrates how to set up automated embedding generation workflows and perform semantic search using LangChain.
content_type: tutorial
filter: sdk
technology:
  - vector search
tags:
  - Hyperscale Vector Index
  - Artificial Intelligence
  - LangChain
sdk_language:
  - python
length: 20 Mins
---


<!--- *** WARNING ***: Autogenerated markdown file from jupyter notebook. ***DO NOT EDIT THIS FILE***. Changes should be made to the original notebook file. See commit message for source repo. -->


[View Source](https://github.com/couchbase-examples/vector-search-cookbook/tree/main/autovec-structured/autovec_langchain.ipynb)

# Create and Deploy Operational Cluster on Capella
To get started with Couchbase Capella, create an account and use it to deploy a cluster. 

Make sure that you deploy a `Multi-node` cluster with `data`, `index`, `query` and `eventing` services enabled. To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).
 ## Couchbase Capella Configuration
 When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met:
   * Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the travel-sample bucket (Read and Write) used in the application.
   * [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running.

# Data Upload and Preparation

There are various techniques that exist to insert data into the cluster. For this tutorial we will be importing sample data set named as `travel-sample`, please follow the steps mentioned below to import the data:

* Go to Data Tools  Import.

* Choose Load sample data.

* Choose a sample named `travel-sample`

* Click Import.

To know moer about different methods how you can import the data on capella, please visit the following [link](https://docs.couchbase.com/cloud/guides/load.html).

After data import is complete, follow the next steps to achieve vectorization for your required fields.

# Deploying the Model
Now, before we actually create embeddings for the documents, we need to deploy a model that will create the embeddings for us. 

> **⚠️ IMPORTANT:** The model **must** be deployed in the **same region** as your database cluster for workflows to function properly. Failing to match regions will prevent the workflow from working and may require cluster redeployment.

## Selecting the Model 
1. To select the model, you first need to navigate to the "<B>AI Services</B>" tab, then select "<B>Models</B>" and click on "<B>Deploy New Model</B>".
   
   <img src="./img/importing_model.png" width="950px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

2. Enter the <B>model name</B>, and choose the model that you want to deploy. After selecting your model, choose the <B>model infrastructure</B> and <B>region</B> where the model will be deployed. **Ensure this matches your database cluster region.**
   
   <img src="./img/deploying_model.png" width="800px" height="800px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

## Access Control to the Model

1. After deploying the model, go to the "<B>Models</B>" tab in the <B>AI Services</B> and click on "<B>Setup Access</B>".

    <img src="./img/model_setup_access.png" width="1100px" height="400px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

2. Enter your <B>API key name</B>, <B>expiration time</B> and the <B>IP address</B> from which you will be accessing the model.

    <img src="./img/model_api_key_form.png" width="1100px" height="600px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

3. Download your API key

   <img src="./img/download_api_key_details.png" width="1200px" height="800px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">


## Deploying AutoVectorization Workflow

Now, we are at the step that will help us create the embeddings/vectors. To proceed with the vectorization process, please follow the steps below. For more details, refer to the [data processing documentation](https://docs.couchbase.com/ai/build/vectorization-service/data-processing.html).

1. For deploying the autovectorization, you need to go to the <B>`AI Services`</B> tab, then click on <B>`Workflows`</B>, and then click on <B>`Create New Workflow`</B>.

   <img src="./img/workflow.png" width="1000px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">
   
2. Start your workflow deployment by giving it a name and selecting where your data will be provided to the auto-vectorization service. There are currently 3 options: <B>`pre-processed data (JSON format) from Capella`</B>, <B>`pre-processed data (JSON format) from external sources (S3 buckets)`</B> and <B>`unstructured data from external sources (S3 buckets)`</B>. For this tutorial, we will choose the first option, which is pre-processed data from Capella.

   <img src="./img/start_workflow.png" width="1000px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

3. Now, select the <B>`cluster`</B>, <B>`bucket`</B>, <B>`scope`</B> and <B>`collection`</B> from which you want to select the documents and get the data vectorized.

   <img src="./img/vector_data_source.png" width="1000px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

4. <B>Field Mapping</B> will be used to tell the AutoVectorize service which data will be converted to embeddings.

   For this tutorial, we use the <B>Custom source fields</B> approach to vectorize specific, semantically meaningful fields. This is more realistic than vectorizing all fields, as it focuses on content-rich fields that are relevant for semantic search.
   
   We select the following fields to be converted into a single vector with the name <B>`vec_descr_review_state`</B>:
   - <B>`description`</B> - The hotel description
   - <B>`reviews`</B> - Customer reviews
   - <B> `state` </B> - State 

   <img src="./img/vector_custom_field_mapping.png" width="900px" height="400px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">
  
5. After choosing the type of mapping, you can optionally create a vector index on the new vector embedding field. While vector search will work without an index using brute force, creating an index is **highly recommended** for better performance, especially with larger datasets.

   <img src="./img/vector_index.png" width="1000px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

6. Below screenshot highlights the whole process which were mentioned above, and click next afterwards as shown below. We will be going ahead with the custom source field mappings for this tutorial.

   <img src="./img/vector_index_page.png" width="900px" height="1200px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">


7. Select the model which will be used to create the embeddings. There are two options to create the embeddings, `capella based` and `external model`.
   
   <img src="./img/Select_embedding_model.png" width="500px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

   - For this tutorial, capella based embedding model is used as can be seen in the image above. API credentials can be uploaded using the file downloaded during model setup section or it can be entered manually as well.
   - Choices between private and insecure networking is available to choose.
   - A click on `Next` will land you at the final page of the workflow.



8.  <B>`Workflow Summary`</B> will display all the necessary details of the workflow including `Data Source`, `Model Service` and `Billing Overview` as shown in image below.

    <img src="./img/workflow_summary.png" width="500px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">



9. <B>`Hurray! Workflow Deployed`</B> Now in the `workflow` tab we can see the workflow deployed and can check the status of our workflow run.

      <img src="./img/workflow_deployed.png" width="1150px" height="500px" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

After this step, your vector embeddings for the selected fields should be ready and you can checkout in your document schema a vector field should be there as highlighter below in the image.
    

<img src="./img/vector_field.png" style="padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;">

In the next step, we will demonstrate how we can use the generated vectors to perform vector search.


# Vector Search

The following code cells implement semantic vector search against the embeddings generated by the AutoVectorization workflow. These searches are powered by **Couchbase's Vector Search service using Hyperscale Indexes**.

Before you proceed, make sure the following packages are installed by running:


```python
!pip install langchain-couchbase==1.0.1 langchain-openai
```

**Required versions:**
- `langchain-couchbase = 1.0.1` (supports QueryVectorStore)
- `langchain-openai` (latest version)

Now, please proceed to execute the cells in order to run the vector similarity search.

# Importing Required Packages



```python
from couchbase.cluster import Cluster
from couchbase.auth import PasswordAuthenticator
from couchbase.options import ClusterOptions

from langchain_openai import OpenAIEmbeddings
from langchain_couchbase.vectorstores import CouchbaseQueryVectorStore
from langchain_couchbase.vectorstores import DistanceStrategy

from datetime import timedelta
```

# Cluster Connection Setup
   - Defines the secure connection string, user credentials, and creates a `Cluster` object.


```python
# Replace with your Capella connection details

endpoint = "COUCHBASE_CAPELLA_ENDPOINT"  # Connection String
username = "COUCHBASE_CAPELLA_USERNAME"  # Capella Username
password = "COUCHBASE_CAPELLA_PASSWORD"  # Capella Password

auth = PasswordAuthenticator(username, password)
options = ClusterOptions(auth)

cluster = Cluster(endpoint, options)
cluster.wait_until_ready(timedelta(seconds=5))
```

# Selection of Buckets / Scope / Collection / Index / Embedder
   - Sets the bucket, scope, and collection where the documents (with vector fields) live.
   - `embedder` instantiates the NVIDIA embedding model that will transform the user's natural language query into a vector at search time.
       - `open_api_key` is the api key token created during model deployment.
       - `open_api_base` is the Capella model services endpoint found in the models section.
       - for more details visit [openAIEmbeddings](https://docs.langchain.com/oss/python/integrations/text_embedding/openai).

`Note that the Capella AI Endpoint also requires an additional /v1 from the endpoint if not shown on the UI`


```python
bucket_name = "travel-sample"
scope_name = "inventory"
collection_name = "hotel"

# Using the OpenAI SDK with Capella model services (compatible with OpenAIEmbeddings)
embedder = OpenAIEmbeddings(
    model="nvidia/llama-3.2-nv-embedqa-1b-v2",  # Query embedding model
    openai_api_key="COUCHBASE_CAPELLA_MODEL_API_KEY",  # Replace with your API key
    openai_api_base="COUCHBASE_CAPELLA_ENDPOINT/v1",  # Add /v1 to endpoint
    check_embedding_ctx_length=False,
    tiktoken_enabled=False,
)

```

# VectorStore Construction
   - Creates a [CouchbaseQueryVectorStore](https://couchbase-ecosystem.github.io/langchain-couchbase/langchain_couchbase.html#couchbase-query-vector-store) instance that interfaces with **Couchbase's Query service** to perform vector similarity searches using [Hyperscale/Composite](https://docs.couchbase.com/cloud/vector-index/use-vector-indexes.html) indexes. 
   - The vector store:
     * Knows where to read documents (`bucket/scope/collection`).
     * Knows the embedding field (the vector produced by the Auto-Vectorization workflow).
     * Uses the provided embedder to embed queries on-demand for similarity search.
   - `text_key` specifies the primary field to display in results (we use `name` for hotel names).
   - `embedding_key` specifies the vector field name that contains the embeddings (must match the field name from the workflow).



```python
vector_store = CouchbaseQueryVectorStore(
    cluster=cluster,
    bucket_name=bucket_name,
    scope_name=scope_name,
    collection_name=collection_name,
    embedding=embedder,
    text_key="name",  # Primary field to display (hotel name)
    embedding_key="hyperscale_autovec_workflow_vec_descr_review_state",  # Vector field from workflow
    distance_metric=DistanceStrategy.DOT
)
```

# Performing a Similarity Search
   - Defines a natural language query to search for hotels based on infrastructure and service quality.
   - Calls `similarity_search(k=3)` to retrieve the top 3 most semantically similar documents.
   - Each result contains:
     * `page_content`: The value of `text_key` (hotel name)
     * `metadata`: Additional fields like description, reviews, city, country, and address
   - Change `query` to any descriptive phrase (e.g., "budget friendly hotel near the beach").
   - Adjust `k` for more or fewer results.



```python
query = "Which hotels have good food?"
results = vector_store.similarity_search(query, k=3, fields=["reviews"])

for i, doc in enumerate(results, 1):
    print(f"\n--- Result {i} ---")
    print(f"Hotel Name: {doc.page_content}")
    print(f"Reviews:")
    received_reviews = doc.metadata["reviews"]
    for j, review in enumerate(received_reviews, 1):
        print(f"Author: {review["author"]}")
        print(f"Content: {review["content"]}\n")
```

    
    --- Result 1 ---
    Hotel Name: Medway Youth Hostel
    Reviews:
    Author: Ozella Sipes
    Content: This was our 2nd trip here and we enjoyed it as much or more than last year. Excellent location across from the French Market and just across the street from the streetcar stop. Very convenient to several small but good restaurants. Very clean and well maintained. Housekeeping and other staff are all friendly and helpful. We really enjoyed sitting on the 2nd floor terrace over the entrance and "people-watching" on Esplanade Ave., also talking with our fellow guests. Some furniture could use a little updating or replacement, but nothing major.
    
    Author: Barton Marks
    Content: We found the hotel de la Monnaie through Interval and we thought we'd give it a try while we attended a conference in New Orleans. This place was a perfect location and it definitely beat staying downtown at the Hilton with the rest of the attendees. We were right on the edge of the French Quarter withing walking distance of the whole area. The location on Esplanade is more of a residential area so you are near the fun but far enough away to enjoy some quiet downtime. We loved the trolly car right across the street and we took that down to the conference center for the conference days we attended. We also took it up Canal Street and nearly delivered to the WWII museum. From there we were able to catch a ride to the Garden District - a must see if you love old architecture - beautiful old homes(mansions). We at lunch ate Joey K's there and it was excellent. We ate so many places in the French Quarter I can't remember all the names. My husband loved all the NOL foods - gumbo, jambalya and more. I'm glad we found the Louisiana Pizza Kitchen right on the other side of the U.S. Mint (across the street from Monnaie). Small little spot but excellent pizza! The day we arrived was a huge jazz festival going on across the street. However, once in our rooms, you couldn't hear any outside noise. Just the train at night blowin it's whistle! We enjoyed being so close to the French Market and within walking distance of all the sites to see. And you can't pass up the Cafe du Monde down the street - a busy happenning place with the best French dougnuts!!!Delicious! We will defintely come back and would stay here again. We were not hounded to purchase anything. My husband only received one phone call regarding timeshare and the woman was very pleasant. The staff was laid back and friendly. My only complaint was the very firm bed. Other than that, we really enjoyed our stay. Thanks Hotel de la Monnaie!
    
    
    --- Result 2 ---
    Hotel Name: The Balmoral Guesthouse
    Reviews:
    
    --- Result 3 ---
    Hotel Name: The Robins
    Reviews:
    Author: Blaise O'Connell IV
    Content: Staff need a bit of a refresher in customer service...we couldn't get a safe and there were 6 of us - "sorry, none left" and not too helpful, the location was terrific but the staff let us down...no water to drink in the rooms - no bar fridge or coffee making facilities...there is a bar next door which is okay - serves breakfast & lunch & dinner...stay here only for the location
    
    Author: Nedra Cronin
    Content: We ended up choosing the Holiday Inn because it had a combination of a low price and a really convenient location. It's close to some great restaurants and just far enough from Bourbon street so that it isn't noisy. The indoor pool on the 10th floor was nice, too. No complaints here.
    
    Author: Marianna Schmeler
    Content: I must explain this history in order that you know what kind of hotel you are going to stay. 2011- Mardi Grass. During the week of the 9th March, we stayed at this hotel for a few days. When we checked out, we drove direction Baton Rouge. As we arrived, we found out that my husband had lost his back bag with all documents, passport, computer, etc. somewhere... The recepcionist in Super 8 La Place helped us a lot. We were very nervous, and she even let us phone to New Orleans just to check if our bag was there. No news, but finally, we decided to drove back to New Orleans. As we arrived the recepcionist, Nimahs, helped us a lot! Security guy, Dal, also. But as they didnÂ´t know about the lost bag, we asked to check the security cameras. The responsible guy came, and checked the cameras with my husband. Thanks to that, the bag was found! Happy end of the history thanks to that people! No one accepted any tips from us. We surely will recomend Super 8 hotels from now on. On the other hand, I must say that this is not a well located hotel if you want to party every night in the French Quarter. But we thought it was a good choice, also thinking about prices, and because we had our own car.
    
    Author: Davon Price
    Content: Nice staff, road trip for our family and wanted cheap but clean. And close to French quarter.
    
    Author: Joannie Barrows DDS
    Content: We read reviews of motels in New Orleans before choosing this one based on good feedback from others. It turned out to be a good choice, for it was a comfortable stay and the staff obviously put a lot of effort into making it a quality establishment. When we left they even had staff doing work in the garden. The room itself was good, with two beds, a fridge and coffee maker. Amazingly, the wifi also worked in the room, which I found to be something of a rarity for places in this price range. The floor sloped slightly downwards, which was a bit odd, but it didn't matter at all. There is plenty of parking, even if the spaces are quite tight. The motel is equipped with a gym, which I didn't use, plus an outdoor pool, which looked quite good but was far too cold when I was there. The business center was very useful, for I was able to print out flight tickets. Breakfast was good (though waffles would enhance it!), but was packed away promptly at 9:30. It was good to fill up in the morning while watching the news before going into New Orleans for the day. That brings me to the location - it's not in an area that you'd want to walk around, but isn't too far from fast food places and is very close to the interstate, so it's easy to get into New Orleans itself. A lot of the motels in New Orleans are in this area. This is an impressive motel and I would happily stay here again if I was every lucky enough to be able to return to New Orleans.
    


## Results and Interpretation

The search results display the top 3 (or `k`) most semantically similar hotels based on your query.

**What you see in each result:**
- **Hotel Name** (`page_content`): The value from the `text_key` field (hotel name).
- **Metadata fields**:
  - `reviews`: Customer reviews

### How the Ranking Works
1. Your natural language query (e.g., `"Which hotels have good food?"`) is embedded using the NVIDIA model (`nvidia/llama-3.2-nv-embedqa-1b-v2`).
2. The query embedding is compared against the `vec_descr_review_state` field in each document using dot product similarity.
3. Results are sorted by vector similarity. Higher similarity = closer semantic meaning.

### Key Observations
- The results are ranked by **semantic similarity**, not keyword matching. Hotels that conceptually match your query about "infrastructure" and "service" will rank higher, even if those exact words don't appear in the document.
- By including extra `fields`, you get rich, contextual information beyond just the hotel name, making the results more actionable.
- The embedding combines `description`, `reviews` and `state` fields, so the search understands the hotel's overall quality based on multiple data points.

> Your vector search pipeline is working if the returned documents feel meaningfully related to your natural language query—even when exact keywords do not match. Feel free to experiment with increasingly descriptive queries to observe the semantic power of the embeddings.



